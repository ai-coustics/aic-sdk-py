{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ai-coustics SDK for Python","text":"<p>Welcome to the ai-coustics real-time speech enhancement SDK for Python.</p> <p>This package provides Python bindings and binaries for high-quality, low-latency neural audio enhancement.</p> <p>Highlights:</p> <ul> <li>Real-time processing optimized for streaming</li> <li>Multiple model sizes: QUAIL_L, QUAIL_S, QUAIL_XS</li> <li>Simple, Pythonic API with context-manager support</li> </ul> <p>Quick example:</p> <pre><code>import os\nimport numpy as np\nfrom dotenv import load_dotenv\nfrom aic import Model, AICModelType, AICParameter\n\nload_dotenv()\nlicense_key = os.getenv(\"AICOUSTICS_API_KEY\", \"\")\n\nwith Model(AICModelType.QUAIL_L, license_key=license_key) as model:\n    model.initialize(sample_rate=48000, channels=1, frames=480)\n    model.set_parameter(AICParameter.ENHANCEMENT_LEVEL, 0.8)\n\n    audio = np.random.randn(1, 480).astype(np.float32)\n    enhanced = model.process(audio)\n</code></pre> <p>Use the navigation to learn how to get started and explore the full API.</p>"},{"location":"api/","title":"API Reference","text":"<p>RAII + context-manager convenience around the C interface.</p> <p>Parameters:</p> <ul> <li> <code>model_type</code>               (<code>AICModelType</code>, default:                   <code>QUAIL_L</code> )           \u2013            <p>The neural model variant to load; defaults to :pydata:<code>AICModelType.QUAIL_L</code>.</p> </li> <li> <code>license_key</code>               (<code>str | bytes</code>, default:                   <code>None</code> )           \u2013            <p>Optional signed license string.  Empty string means trial mode.</p> </li> </ul> <p>Create a model wrapper.</p> <p>Parameters:</p> <ul> <li> <code>model_type</code>               (<code>AICModelType</code>, default:                   <code>QUAIL_L</code> )           \u2013            <p>The neural model variant to load; defaults to :pydata:<code>AICModelType.QUAIL_L</code>.</p> </li> <li> <code>license_key</code>               (<code>str | bytes</code>, default:                   <code>None</code> )           \u2013            <p>Signed license string. Required. Obtain a key at https://developers.ai-coustics.io.</p> </li> </ul> <p>Available neural model variants.</p> <p>Algorithm parameters adjustable at runtime.</p>"},{"location":"api/#aic.Model.close","title":"<code>close()</code>","text":"<p>Explicitly free native resources (idempotent).</p>"},{"location":"api/#aic.Model.get_parameter","title":"<code>get_parameter(param)</code>","text":"<p>Get the current value of a parameter.</p> <p>Parameters:</p> <ul> <li> <code>param</code>               (<code>AICParameter</code>)           \u2013            <p>Parameter enum value. See :py:class:<code>aic._bindings.AICParameter</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The current value of the parameter.</p> </li> </ul>"},{"location":"api/#aic.Model.initialize","title":"<code>initialize(sample_rate, channels, frames)</code>","text":"<p>Allocate internal DSP state.</p> <p>Parameters:</p> <ul> <li> <code>sample_rate</code>               (<code>int</code>)           \u2013            <p>Input/output sample rate in Hz.</p> </li> <li> <code>channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the processed audio (e.g., 1 for mono, 2 for stereo).</p> </li> <li> <code>frames</code>               (<code>int</code>)           \u2013            <p>Block length in frames for streaming. Use :py:meth:<code>optimal_num_frames</code> for a recommended value.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the underlying SDK rejects the configuration.</p> </li> </ul>"},{"location":"api/#aic.Model.library_version","title":"<code>library_version()</code>  <code>staticmethod</code>","text":"<p>Return the version string of the underlying AIC SDK library.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Semantic version string.</p> </li> </ul>"},{"location":"api/#aic.Model.optimal_num_frames","title":"<code>optimal_num_frames()</code>","text":"<p>Return the suggested buffer length for streaming.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Recommended block size in frames.</p> </li> </ul>"},{"location":"api/#aic.Model.optimal_sample_rate","title":"<code>optimal_sample_rate()</code>","text":"<p>Return the suggested I/O sample rate for the loaded model.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Sample rate in Hz.</p> </li> </ul>"},{"location":"api/#aic.Model.process","title":"<code>process(pcm, *, channels=None)</code>","text":"<p>Enhance pcm in-place using planar processing (convenience pass-through).</p> <p>Parameters:</p> <ul> <li> <code>pcm</code>               (<code>ndarray</code>)           \u2013            <p>Planar 2-D array of shape (channels, frames) Data must be <code>float32</code> in the linear -1\u2026+1 range. Any non-conforming array is copied to a compliant scratch buffer.</p> </li> <li> <code>channels</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Override channel count auto-detected from pcm.  Rarely needed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The same array instance (modified in-place) or a contiguous copy if a dtype/stride conversion had been necessary.</p> </li> </ul>"},{"location":"api/#aic.Model.process_interleaved","title":"<code>process_interleaved(pcm, channels)</code>","text":"<p>Enhance pcm in-place using interleaved processing (convenience pass-through).</p> <p>Parameters:</p> <ul> <li> <code>pcm</code>               (<code>ndarray</code>)           \u2013            <p>Interleaved 1-D array of shape (frames,) containing interleaved audio data Data must be <code>float32</code> in the linear -1\u2026+1 range. Any non-conforming array is copied to a compliant scratch buffer.</p> </li> <li> <code>channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the interleaved data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The same array instance (modified in-place) or a contiguous copy if a dtype/stride conversion had been necessary.</p> </li> </ul>"},{"location":"api/#aic.Model.processing_latency","title":"<code>processing_latency()</code>","text":"<p>Return the current internal group delay.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Algorithmic latency in frames.</p> </li> </ul>"},{"location":"api/#aic.Model.reset","title":"<code>reset()</code>","text":"<p>Flush the model's internal state (between recordings, etc.).</p>"},{"location":"api/#aic.Model.set_parameter","title":"<code>set_parameter(param, value)</code>","text":"<p>Update an algorithm parameter.</p> <p>Parameters:</p> <ul> <li> <code>param</code>               (<code>AICParameter</code>)           \u2013            <p>Parameter enum value. See :py:class:<code>aic._bindings.AICParameter</code>.</p> </li> <li> <code>value</code>               (<code>float</code>)           \u2013            <p>New value for the parameter (float).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the parameter is out of range or the SDK call fails.</p> </li> </ul>"},{"location":"api/#aic._bindings.AICModelType.LEGACY_L","title":"<code>LEGACY_L = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Legacy large model - 512-frame, ~10.67ms latency.</p>"},{"location":"api/#aic._bindings.AICModelType.LEGACY_S","title":"<code>LEGACY_S = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Legacy small model - 256-frame, ~5.33ms latency.</p>"},{"location":"api/#aic._bindings.AICModelType.QUAIL_L","title":"<code>QUAIL_L = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Large model - highest quality, higher compute usage.</p>"},{"location":"api/#aic._bindings.AICModelType.QUAIL_S","title":"<code>QUAIL_S = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Small model - balanced quality and speed.</p>"},{"location":"api/#aic._bindings.AICModelType.QUAIL_XS","title":"<code>QUAIL_XS = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Extra small model - fastest, lower quality.</p>"},{"location":"api/#aic._bindings.AICModelType.QUAIL_XXS","title":"<code>QUAIL_XXS = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ultra small model - lowest latency, minimal compute.</p>"},{"location":"api/#aic._bindings.AICParameter.BYPASS","title":"<code>BYPASS = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Bypass processing (0.0 off \u2192 1.0 on).</p>"},{"location":"api/#aic._bindings.AICParameter.ENHANCEMENT_LEVEL","title":"<code>ENHANCEMENT_LEVEL = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Overall enhancement strength (0.0 \u2026 1.0).</p>"},{"location":"api/#aic._bindings.AICParameter.ENHANCEMENT_LEVEL_SKEW_FACTOR","title":"<code>ENHANCEMENT_LEVEL_SKEW_FACTOR = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Skew factor for non-linear enhancement mapping.</p>"},{"location":"api/#aic._bindings.AICParameter.NOISE_GATE_ENABLE","title":"<code>NOISE_GATE_ENABLE = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Enable/disable noise gate (0.0 off \u2192 1.0 on).</p>"},{"location":"api/#aic._bindings.AICParameter.VOICE_GAIN","title":"<code>VOICE_GAIN = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Additional gain applied to detected speech (linear).</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#enhance-a-wav-file","title":"Enhance a WAV file","text":"<pre><code>AICOUSTICS_API_KEY=your_key_here python examples/enhance.py input.wav output.wav --strength 80\n</code></pre>"},{"location":"examples/#streaming-like-chunked-processing","title":"Streaming-like chunked processing","text":"<pre><code>import numpy as np\nfrom aic import Model, AICModelType\n\nwith Model(AICModelType.QUAIL_S) as model:\n    model.initialize(sample_rate=48000, channels=1, frames=480)\n\n    audio_stream = ...  # your audio input\n    while audio_stream.has_data():\n        chunk = audio_stream.get_chunk(480)\n        enhanced = model.process(chunk)\n        # play or store `enhanced`\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install aic-sdk\n</code></pre> <p>For examples: <pre><code>pip install -r examples/requirements.txt\n</code></pre></p>"},{"location":"getting-started/#license-key","title":"License Key","text":"<p>Set the environment variable (or use a <code>.env</code> file), and pass it to the model.</p> <pre><code>export AICOUSTICS_API_KEY=\"your_license_key\"\n</code></pre> <p>or in <code>.env</code>: <pre><code>AICOUSTICS_API_KEY=your_license_key\n</code></pre></p>"},{"location":"getting-started/#first-enhancement","title":"First Enhancement","text":"<pre><code>import os\nimport numpy as np\nfrom dotenv import load_dotenv\nfrom aic import Model, AICModelType, AICParameter\n\nload_dotenv()\nlicense_key = os.getenv(\"AICOUSTICS_API_KEY\")\n\nwith Model(AICModelType.QUAIL_L, license_key=license_key) as model:\n    model.initialize(sample_rate=48000, channels=1, frames=480)\n    model.set_parameter(AICParameter.ENHANCEMENT_LEVEL, 0.7)\n\n    audio = np.random.randn(1, 480).astype(np.float32)\n    enhanced = model.process(audio)\n</code></pre> <ul> <li>Use <code>optimal_num_frames()</code> to get a recommended buffer size for streaming.</li> <li>Use <code>optimal_sample_rate()</code> for the preferred I/O sample rate.</li> </ul>"}]}