{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ai-coustics SDK for Python","text":"<p>Welcome to the ai-coustics real-time speech enhancement SDK for Python.</p> <p>This package provides Python bindings and binaries for high-quality, low-latency neural audio enhancement.</p> <p>Highlights:</p> <ul> <li>Real-time processing optimized for streaming</li> <li>Multiple model sizes: QUAIL_L, QUAIL_S, QUAIL_XS, QUAIL_XXS</li> <li>STT-optimized models: QUAIL_STT_L16, QUAIL_STT_L8, QUAIL_STT_S16, QUAIL_STT_S8, QUAIL_VF_STT_L16</li> <li>Simple, Pythonic API with context-manager support</li> <li>Built-in Voice Activity Detection (VAD) powered by the Quail model family</li> <li>Multiple processing layouts: planar, interleaved, and sequential</li> </ul> <p>Quick example:</p> <pre><code>import os\nimport numpy as np\nfrom dotenv import load_dotenv\nfrom aic import Model, AICModelType, AICParameter\n\nload_dotenv()\nlicense_key = os.getenv(\"AIC_SDK_LICENSE\", \"\")\n\nwith Model(AICModelType.QUAIL_L, license_key=license_key, sample_rate=48000, channels=1, frames=480) as model:\n    model.set_parameter(AICParameter.ENHANCEMENT_LEVEL, 0.8)\n\n    audio = np.random.randn(1, 480).astype(np.float32)\n    enhanced = model.process(audio)\n</code></pre> <p>Use the navigation to learn how to get started and explore the full API.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#model-class","title":"Model Class","text":""},{"location":"api/#aic.Model","title":"<code>aic.Model(model_type=AICModelType.QUAIL_L, license_key=None, *, sample_rate, channels=1, frames=None, allow_variable_frames=False)</code>","text":"<p>RAII + context-manager convenience around the C interface.</p> <p>Parameters:</p> <ul> <li> <code>model_type</code>               (<code>AICModelType</code>, default:                   <code>QUAIL_L</code> )           \u2013            <p>The neural model variant to load; defaults to :pydata:<code>AICModelType.QUAIL_L</code>.</p> </li> <li> <code>license_key</code>               (<code>str | bytes</code>, default:                   <code>None</code> )           \u2013            <p>Optional signed license string.  Empty string means trial mode.</p> </li> </ul> <p>Create a model wrapper.</p> <p>Parameters:</p> <ul> <li> <code>model_type</code>               (<code>AICModelType</code>, default:                   <code>QUAIL_L</code> )           \u2013            <p>The neural model variant to load; defaults to :pydata:<code>AICModelType.QUAIL_L</code>.</p> </li> <li> <code>license_key</code>               (<code>str | bytes</code>, default:                   <code>None</code> )           \u2013            <p>Signed license string. Required. Obtain a key at https://developers.ai-coustics.io.</p> </li> <li> <code>sample_rate</code>               (<code>int</code>)           \u2013            <p>Input/output sample rate in Hz. Required.</p> </li> <li> <code>channels</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Channel count. Optional, defaults to 1.</p> </li> <li> <code>frames</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional block length in frames for streaming. If omitted, the model's :py:meth:<code>optimal_num_frames</code> will be used.</p> </li> </ul>"},{"location":"api/#aic.Model.close","title":"<code>close()</code>","text":"<p>Explicitly free native resources (idempotent).</p>"},{"location":"api/#aic.Model.create_vad","title":"<code>create_vad()</code>","text":"<p>Create a Voice Activity Detector bound to this model.</p>"},{"location":"api/#aic.Model.get_parameter","title":"<code>get_parameter(param)</code>","text":"<p>Get the current value of a parameter.</p> <p>Parameters:</p> <ul> <li> <code>param</code>               (<code>AICParameter | AICEnhancementParameter</code>)           \u2013            <p>Parameter enum value. See :py:class:<code>aic._bindings.AICEnhancementParameter</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The current value of the parameter.</p> </li> </ul>"},{"location":"api/#aic.Model.library_version","title":"<code>library_version()</code>  <code>staticmethod</code>","text":"<p>Return the version string of the underlying AIC SDK library.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Semantic version string.</p> </li> </ul>"},{"location":"api/#aic.Model.optimal_num_frames","title":"<code>optimal_num_frames()</code>","text":"<p>Return the suggested buffer length for streaming.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Recommended block size in frames.</p> </li> </ul>"},{"location":"api/#aic.Model.optimal_sample_rate","title":"<code>optimal_sample_rate()</code>","text":"<p>Return the suggested I/O sample rate for the loaded model.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Sample rate in Hz.</p> </li> </ul>"},{"location":"api/#aic.Model.process","title":"<code>process(pcm, *, channels=None)</code>","text":"<p>Enhance <code>pcm</code> in-place using planar processing (convenience pass-through).</p> <p>Parameters:</p> <ul> <li> <code>pcm</code>               (<code>ndarray</code>)           \u2013            <p>Planar 2-D array of shape <code>(channels, frames)</code> Data must be <code>float32</code> in the linear -1\u2026+1 range. Any non-conforming array is copied to a compliant scratch buffer.</p> </li> <li> <code>channels</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Override channel count auto-detected from <code>pcm</code>.  Rarely needed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The same array instance (modified in-place) or a contiguous copy if a dtype/stride conversion had been necessary.</p> </li> </ul>"},{"location":"api/#aic.Model.process_async","title":"<code>process_async(pcm, *, channels=None)</code>  <code>async</code>","text":"<p>Async variant of :py:meth:<code>process</code> executed on the model's worker thread.</p>"},{"location":"api/#aic.Model.process_interleaved","title":"<code>process_interleaved(pcm, channels)</code>","text":"<p>Enhance <code>pcm</code> in-place using interleaved processing (convenience pass-through).</p> <p>Parameters:</p> <ul> <li> <code>pcm</code>               (<code>ndarray</code>)           \u2013            <p>Interleaved 1-D array of shape <code>(frames,)</code> containing interleaved audio data Data must be <code>float32</code> in the linear -1\u2026+1 range. Any non-conforming array is copied to a compliant scratch buffer.</p> </li> <li> <code>channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the interleaved data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The same array instance (modified in-place) or a contiguous copy if a dtype/stride conversion had been necessary.</p> </li> </ul>"},{"location":"api/#aic.Model.process_interleaved_async","title":"<code>process_interleaved_async(pcm, channels)</code>  <code>async</code>","text":"<p>Async variant of :py:meth:<code>process_interleaved</code> executed on the model's worker thread.</p>"},{"location":"api/#aic.Model.process_interleaved_submit","title":"<code>process_interleaved_submit(pcm, channels)</code>","text":"<p>Submit :py:meth:<code>process_interleaved</code> to the worker thread, returning a Future.</p>"},{"location":"api/#aic.Model.process_sequential","title":"<code>process_sequential(pcm, channels)</code>","text":"<p>Enhance <code>pcm</code> in-place using sequential channel data processing.</p> <p>Processes audio where all samples for each channel are stored sequentially (channel 0 samples, then channel 1 samples, etc.) rather than interleaved.</p> <p>Parameters:</p> <ul> <li> <code>pcm</code>               (<code>ndarray</code>)           \u2013            <p>Sequential 1-D array of shape <code>(frames * channels,)</code> containing sequential audio data where all samples for channel 0 come first, followed by all samples for channel 1, etc. Data must be <code>float32</code> in the linear -1\u2026+1 range. Any non-conforming array is copied to a compliant scratch buffer.</p> </li> <li> <code>channels</code>               (<code>int</code>)           \u2013            <p>Number of channels in the sequential data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The same array instance (modified in-place) or a contiguous copy if a dtype/stride conversion had been necessary.</p> </li> </ul>"},{"location":"api/#aic.Model.process_sequential_async","title":"<code>process_sequential_async(pcm, channels)</code>  <code>async</code>","text":"<p>Async variant of :py:meth:<code>process_sequential</code> executed on the model's worker thread.</p>"},{"location":"api/#aic.Model.process_sequential_submit","title":"<code>process_sequential_submit(pcm, channels)</code>","text":"<p>Submit :py:meth:<code>process_sequential</code> to the worker thread, returning a Future.</p>"},{"location":"api/#aic.Model.process_submit","title":"<code>process_submit(pcm, *, channels=None)</code>","text":"<p>Submit :py:meth:<code>process</code> to the model's worker thread, returning a Future.</p>"},{"location":"api/#aic.Model.processing_latency","title":"<code>processing_latency()</code>","text":"<p>Return the current output delay (in samples).</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>End-to-end delay in samples at the configured sample rate.</p> </li> </ul>"},{"location":"api/#aic.Model.reset","title":"<code>reset()</code>","text":"<p>Flush the model's internal state (between recordings, etc.).</p>"},{"location":"api/#aic.Model.set_parameter","title":"<code>set_parameter(param, value)</code>","text":"<p>Update an algorithm parameter.</p> <p>Parameters:</p> <ul> <li> <code>param</code>               (<code>AICParameter | AICEnhancementParameter</code>)           \u2013            <p>Parameter enum value. See :py:class:<code>aic._bindings.AICEnhancementParameter</code>.</p> </li> <li> <code>value</code>               (<code>float</code>)           \u2013            <p>New value for the parameter (float).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the parameter is out of range or the SDK call fails.</p> </li> </ul>"},{"location":"api/#voice-activity-detector","title":"Voice Activity Detector","text":""},{"location":"api/#aic.VoiceActivityDetector","title":"<code>aic.VoiceActivityDetector(model)</code>","text":"<p>Voice Activity Detector bound to a :pyclass:<code>Model</code>.</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#enhance-a-wav-file","title":"Enhance a WAV file","text":"<pre><code>AIC_SDK_LICENSE=your_key_here python examples/enhance.py input.wav output.wav --strength 80\n</code></pre>"},{"location":"examples/#streaming-like-chunked-processing","title":"Streaming-like chunked processing","text":"<pre><code>import numpy as np\nfrom aic import Model, AICModelType\n\nwith Model(AICModelType.QUAIL_S, sample_rate=48000, channels=1, frames=480) as model:\n\n    audio_stream = ...  # your audio input\n    while audio_stream.has_data():\n        chunk = audio_stream.get_chunk(480)\n        enhanced = model.process(chunk)\n        # play or store `enhanced`\n</code></pre>"},{"location":"examples/#voice-activity-detection-vad-during-streaming","title":"Voice Activity Detection (VAD) during streaming","text":"<p>Attach a VAD to a model and query speech activity as you process audio.</p> <pre><code>import numpy as np\nfrom aic import Model, AICModelType, AICVadParameter\n\nwith Model(AICModelType.QUAIL_L, sample_rate=48000, channels=1, frames=480) as model:\n    with model.create_vad() as vad:\n        # Optional: tune VAD behavior\n        vad.set_parameter(AICVadParameter.SPEECH_HOLD_DURATION, 0.05)\n        vad.set_parameter(AICVadParameter.SENSITIVITY, 6.0)\n\n        for chunk in stream_chunks():  # yields (1, 480) float32 arrays\n            model.process(chunk)\n            is_speech = vad.is_speech_detected()\n            if is_speech:\n                handle_active_speech(chunk)\n</code></pre>"},{"location":"examples/#sequential-channel-processing","title":"Sequential channel processing","text":"<p>Process audio where channels are stored sequentially (all samples for channel 0, then channel 1, etc.) rather than interleaved.</p> <pre><code>import numpy as np\nfrom aic import Model, AICModelType\n\n# Sequential layout: [ch0_samples..., ch1_samples..., ...]\nch0 = np.random.randn(480).astype(np.float32)\nch1 = np.random.randn(480).astype(np.float32)\naudio_sequential = np.concatenate([ch0, ch1])  # All ch0, then all ch1\n\nwith Model(AICModelType.QUAIL_L, license_key=license_key, sample_rate=48000, channels=2, frames=480) as model:\n    enhanced = model.process_sequential(audio_sequential, channels=2)\n    # enhanced is modified in-place\n</code></pre>"},{"location":"examples/#stt-optimized-models","title":"STT-optimized models","text":"<p>Use STT-optimized models for speech-to-text applications. These models are designed to improve STT accuracy in challenging environments.</p> <pre><code>import numpy as np\nfrom aic import Model, AICModelType\n\n# For 16 kHz audio (recommended for most STT systems)\nwith Model(AICModelType.QUAIL_STT_L16, license_key=license_key, sample_rate=16000, channels=1, frames=160) as model:\n    audio = np.random.randn(1, 160).astype(np.float32)\n    enhanced = model.process(audio)\n\n# For 8 kHz audio\nwith Model(AICModelType.QUAIL_STT_L8, license_key=license_key, sample_rate=8000, channels=1, frames=80) as model:\n    audio = np.random.randn(1, 80).astype(np.float32)\n    enhanced = model.process(audio)\n\n# Voice Focus model - isolates foreground speaker while suppressing interfering speech\nwith Model(AICModelType.QUAIL_VF_STT_L16, license_key=license_key, sample_rate=16000, channels=1, frames=160) as model:\n    audio = np.random.randn(1, 160).astype(np.float32)\n    enhanced = model.process(audio)\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install aic-sdk\n</code></pre> <p>For examples: <pre><code>pip install -r examples/requirements.txt\n</code></pre></p>"},{"location":"getting-started/#license-key","title":"License Key","text":"<p>Set the environment variable (or use a <code>.env</code> file), and pass it to the model.</p> <pre><code>export AIC_SDK_LICENSE=\"your_license_key\"\n</code></pre> <p>or in <code>.env</code>: <pre><code>AIC_SDK_LICENSE=your_license_key\n</code></pre></p>"},{"location":"getting-started/#first-enhancement","title":"First Enhancement","text":"<pre><code>import os\nimport numpy as np\nfrom dotenv import load_dotenv\nfrom aic import Model, AICModelType, AICParameter\n\nload_dotenv()\nlicense_key = os.getenv(\"AIC_SDK_LICENSE\")\n\nwith Model(AICModelType.QUAIL_L, license_key=license_key, sample_rate=48000, channels=1, frames=480) as model:\n    model.set_parameter(AICParameter.ENHANCEMENT_LEVEL, 0.7)\n\n    # Planar format: (channels, frames) - default processing method\n    audio = np.random.randn(1, 480).astype(np.float32)\n    enhanced = model.process(audio)\n</code></pre>"},{"location":"getting-started/#processing-methods","title":"Processing Methods","text":"<p>The SDK supports three audio layouts:</p> <ol> <li> <p>Planar (default): Separate buffer per channel <code>(channels, frames)</code> <pre><code>audio = np.random.randn(2, 480).astype(np.float32)  # 2 channels, 480 frames\nenhanced = model.process(audio)\n</code></pre></p> </li> <li> <p>Interleaved: Channels interleaved in single buffer <code>(frames * channels,)</code> <pre><code>audio = np.random.randn(960).astype(np.float32)  # 2 channels * 480 frames\nenhanced = model.process_interleaved(audio, channels=2)\n</code></pre></p> </li> <li> <p>Sequential: All samples for channel 0, then channel 1, etc. <code>(frames * channels,)</code> <pre><code>ch0 = np.random.randn(480).astype(np.float32)\nch1 = np.random.randn(480).astype(np.float32)\naudio = np.concatenate([ch0, ch1])  # Sequential layout\nenhanced = model.process_sequential(audio, channels=2)\n</code></pre></p> </li> <li> <p>Use <code>optimal_num_frames()</code> to get a recommended buffer size for streaming.</p> </li> <li>Use <code>optimal_sample_rate()</code> for the preferred I/O sample rate.</li> </ol>"},{"location":"getting-started/#model-types","title":"Model Types","text":"<p>The SDK provides several model families optimized for different use cases:</p> <ul> <li>QUAIL_L / QUAIL_S: General-purpose enhancement models (auto-selects sample rate variant)</li> <li>QUAIL_XS / QUAIL_XXS: Lower latency models for real-time applications</li> <li>QUAIL_STT_*: Models optimized for speech-to-text applications:</li> <li><code>QUAIL_STT_L16</code> - 16 kHz, large variant</li> <li><code>QUAIL_STT_L8</code> - 8 kHz, large variant</li> <li><code>QUAIL_STT_S16</code> - 16 kHz, small variant</li> <li><code>QUAIL_STT_S8</code> - 8 kHz, small variant</li> <li><code>QUAIL_VF_STT_L16</code> - Voice Focus model for isolating foreground speaker</li> </ul> <p>Note: <code>QUAIL_STT</code> is deprecated; use <code>QUAIL_STT_L16</code> instead.</p>"},{"location":"getting-started/#voice-activity-detection-vad","title":"Voice Activity Detection (VAD)","text":"<p>Create a VAD tied to your model to get speech activity predictions with minimal effort.</p> <pre><code>from aic import Model, AICModelType, AICVadParameter\n\nwith Model(AICModelType.QUAIL_L, license_key=license_key, sample_rate=48000, channels=1, frames=480) as model:\n    with model.create_vad() as vad:\n        vad.set_parameter(AICVadParameter.SPEECH_HOLD_DURATION, 0.05)\n        vad.set_parameter(AICVadParameter.SENSITIVITY, 6.0)\n\n        # Drive the model to produce VAD predictions\n        audio = np.random.randn(1, 480).astype(np.float32)\n        model.process(audio)\n        print(\"speech detected:\", vad.is_speech_detected())\n</code></pre>"},{"location":"low-level-bindings/","title":"Low-level C bindings (<code>aic._bindings</code>)","text":"<p>The high-level <code>aic.Model</code> API is recommended for most applications. The low-level bindings mirror the C API and are useful for advanced integrations, benchmarks, or when you need fine-grained control.</p>"},{"location":"low-level-bindings/#core-functions","title":"Core functions","text":""},{"location":"low-level-bindings/#aic._bindings.model_create","title":"<code>aic._bindings.model_create(model_type, license_key)</code>","text":"<p>Create a new audio enhancement model instance.</p> <p>Multiple models can be created to process different audio streams simultaneously or to switch between enhancement algorithms.</p> <p>Parameters:</p> <ul> <li> <code>model_type</code>               (<code>AICModelType</code>)           \u2013            <p>Selects the enhancement algorithm variant.</p> </li> <li> <code>license_key</code>               (<code>bytes</code>)           \u2013            <p>Null-terminated license string. Must not be empty.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>AICModelPtrT</code>           \u2013            <p>Opaque handle to the created model instance.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the underlying C call fails. The error message includes the corresponding :class:<code>AICErrorCode</code> name from the SDK.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.model_destroy","title":"<code>aic._bindings.model_destroy(model)</code>","text":"<p>Release all resources associated with a model instance.</p> <p>Safe to call with a null/invalid handle; the operation is idempotent.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance to destroy. Can be <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.model_initialize","title":"<code>aic._bindings.model_initialize(model, sample_rate, num_channels, num_frames, allow_variable_frames=False)</code>","text":"<p>Configure the model for a specific audio format.</p> <p>Must be called before processing. For the lowest delay use the values returned by :func:<code>get_optimal_sample_rate</code> and :func:<code>get_optimal_num_frames</code>.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model handle. Must not be <code>None</code>.</p> </li> <li> <code>sample_rate</code>               (<code>int</code>)           \u2013            <p>Audio sample rate in Hz (8000\u2013192000).</p> </li> <li> <code>num_channels</code>               (<code>int</code>)           \u2013            <p>Number of audio channels (1 for mono, 2 for stereo, etc.).</p> </li> <li> <code>num_frames</code>               (<code>int</code>)           \u2013            <p>Number of samples per channel per processing call.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the configuration is not supported by the model.</p> </li> </ul> Notes <p>Not real-time safe: do not call from time-critical audio threads.</p>"},{"location":"low-level-bindings/#aic._bindings.model_reset","title":"<code>aic._bindings.model_reset(model)</code>","text":"<p>Clear all internal state and buffers (real-time safe).</p> <p>Call this when the audio stream is interrupted or when seeking to prevent artifacts from previous audio content. The model remains initialized with the same configuration.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance. Must not be <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul>"},{"location":"low-level-bindings/#processing","title":"Processing","text":""},{"location":"low-level-bindings/#aic._bindings.process_planar","title":"<code>aic._bindings.process_planar(model, audio_ptr, num_channels, num_frames)</code>","text":"<p>Process audio in-place with separate buffers per channel (planar layout).</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Initialized model instance.</p> </li> <li> <code>audio_ptr</code>               (<code>Any</code>)           \u2013            <p>Array of channel buffer pointers (<code>float* const*</code> on the C side).</p> </li> <li> <code>num_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels (must match initialization; max 16 channels).</p> </li> <li> <code>num_frames</code>               (<code>int</code>)           \u2013            <p>Number of samples per channel (must match initialization).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the model is not initialized, inputs are null, or the channel/frame configuration does not match the initialization.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.process_interleaved","title":"<code>aic._bindings.process_interleaved(model, audio_ptr, num_channels, num_frames)</code>","text":"<p>Process audio in-place with interleaved channel data.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Initialized model instance.</p> </li> <li> <code>audio_ptr</code>               (<code>Any</code>)           \u2013            <p>Interleaved audio buffer pointer.</p> </li> <li> <code>num_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels (must match initialization).</p> </li> <li> <code>num_frames</code>               (<code>int</code>)           \u2013            <p>Number of frames per channel (must match initialization).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the model is not initialized, inputs are null, or the channel/frame configuration does not match the initialization.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.process_sequential","title":"<code>aic._bindings.process_sequential(model, audio_ptr, num_channels, num_frames)</code>","text":"<p>Process audio in-place with sequential channel data in a single buffer.</p> <p>Processes audio where all samples for each channel are stored sequentially (channel 0 samples, then channel 1 samples, etc.) rather than interleaved.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Initialized model instance.</p> </li> <li> <code>audio_ptr</code>               (<code>Any</code>)           \u2013            <p>Sequential audio buffer pointer containing all samples for channel 0, followed by all samples for channel 1, etc.</p> </li> <li> <code>num_channels</code>               (<code>int</code>)           \u2013            <p>Number of channels (must match initialization).</p> </li> <li> <code>num_frames</code>               (<code>int</code>)           \u2013            <p>Number of frames per channel (must match initialization).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the model is not initialized, inputs are null, or the channel/frame configuration does not match the initialization.</p> </li> </ul>"},{"location":"low-level-bindings/#enhancement-parameters","title":"Enhancement Parameters","text":""},{"location":"low-level-bindings/#aic._bindings.set_parameter","title":"<code>aic._bindings.set_parameter(model, param, value)</code>","text":"<p>Modify a model parameter (thread-safe).</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance. Must not be <code>None</code>.</p> </li> <li> <code>param</code>               (<code>AICEnhancementParameter</code>)           \u2013            <p>Parameter to modify.</p> </li> <li> <code>value</code>               (<code>float</code>)           \u2013            <p>New parameter value. See parameter docs for valid ranges.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the value is outside the acceptable range.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.get_parameter","title":"<code>aic._bindings.get_parameter(model, param)</code>","text":"<p>Retrieve the current value of a parameter (thread-safe).</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance. Must not be <code>None</code>.</p> </li> <li> <code>param</code>               (<code>AICEnhancementParameter</code>)           \u2013            <p>Parameter to query.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The current value of the parameter.</p> </li> </ul>"},{"location":"low-level-bindings/#information-helpers","title":"Information helpers","text":""},{"location":"low-level-bindings/#aic._bindings.get_processing_latency","title":"<code>aic._bindings.get_processing_latency(model)</code>","text":"<p>Return total output delay in samples for the current configuration.</p> Delay behavior <ul> <li>Before initialization: returns the base processing delay using the   model's optimal frame size at its native sample rate.</li> <li>After initialization: returns the actual delay for the configured   sample rate and frame size, including any additional buffering when   using non-optimal frame sizes.</li> </ul> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance. Must not be <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Delay in samples (at the current sample rate). Convert to milliseconds via <code>delay_ms = delay_samples * 1000 / sample_rate</code>.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.get_output_delay","title":"<code>aic._bindings.get_output_delay(model)</code>","text":"<p>Alias of :func:<code>get_processing_latency</code>.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Delay in samples.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.get_optimal_sample_rate","title":"<code>aic._bindings.get_optimal_sample_rate(model)</code>","text":"<p>Return the model's native sample rate in Hz.</p> <p>Each model is optimized for a specific sample rate. While processing at other rates is supported, enhancement quality for high frequencies is bounded by the model's native Nyquist frequency.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Native/optimal sample rate in Hz.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.get_optimal_num_frames","title":"<code>aic._bindings.get_optimal_num_frames(model, sample_rate)</code>","text":"<p>Return the optimal number of frames for minimal latency at a sample rate.</p> <p>Using the optimal frame size avoids internal buffering and thus minimizes end-to-end delay. The optimal value depends on sample rate and updates when the model is initialized with a different rate. Before initialization this returns the optimal size for the provided sample rate.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>AICModelPtrT</code>)           \u2013            <p>Model instance.</p> </li> <li> <code>sample_rate</code>               (<code>int</code>)           \u2013            <p>Sample rate in Hz for which to query the optimal frame count.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Optimal frame count for the current/native sample rate.</p> </li> </ul>"},{"location":"low-level-bindings/#aic._bindings.get_library_version","title":"<code>aic._bindings.get_library_version()</code>","text":"<p>Return the SDK version string.</p> <p>The returned value originates from a static C string and is safe to use for the lifetime of the program.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Semantic version string, for example <code>\"1.2.3\"</code>.</p> </li> </ul>"},{"location":"low-level-bindings/#voice-activity-detection-vad","title":"Voice Activity Detection (VAD)","text":""},{"location":"low-level-bindings/#aic._bindings.vad_create","title":"<code>aic._bindings.vad_create(model)</code>","text":"<p>Create a Voice Activity Detector bound to a model.</p>"},{"location":"low-level-bindings/#aic._bindings.vad_destroy","title":"<code>aic._bindings.vad_destroy(vad)</code>","text":"<p>Destroy a VAD instance (idempotent).</p>"},{"location":"low-level-bindings/#aic._bindings.vad_is_speech_detected","title":"<code>aic._bindings.vad_is_speech_detected(vad)</code>","text":"<p>Return the current VAD prediction.</p>"},{"location":"low-level-bindings/#aic._bindings.vad_set_parameter","title":"<code>aic._bindings.vad_set_parameter(vad, param, value)</code>","text":"<p>Set a VAD parameter.</p>"},{"location":"low-level-bindings/#aic._bindings.vad_get_parameter","title":"<code>aic._bindings.vad_get_parameter(vad, param)</code>","text":"<p>Get a VAD parameter.</p>"},{"location":"low-level-bindings/#enums","title":"Enums","text":""},{"location":"low-level-bindings/#aic._bindings.AICErrorCode","title":"<code>aic._bindings.AICErrorCode</code>","text":"<p>Error codes returned by the C API.</p> <p>These mirror the values from the underlying SDK and are raised as <code>RuntimeError</code> by the thin wrappers in this module when a call does not succeed.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.AUDIO_CONFIG_MISMATCH","title":"<code>AUDIO_CONFIG_MISMATCH = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Process was called with a different audio buffer configuration than initialized.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.AUDIO_CONFIG_UNSUPPORTED","title":"<code>AUDIO_CONFIG_UNSUPPORTED = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Audio configuration is not supported by the model.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.ENHANCEMENT_NOT_ALLOWED","title":"<code>ENHANCEMENT_NOT_ALLOWED = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SDK key not authorized or usage reporting failed (check internet connection).</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.INTERNAL_ERROR","title":"<code>INTERNAL_ERROR = 7</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Internal error occurred. Contact support.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.LICENSE_EXPIRED","title":"<code>LICENSE_EXPIRED = 52</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>License key has expired.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.LICENSE_FORMAT_INVALID","title":"<code>LICENSE_FORMAT_INVALID = 50</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>License key format is invalid or corrupted.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.LICENSE_VERSION_UNSUPPORTED","title":"<code>LICENSE_VERSION_UNSUPPORTED = 51</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>License version is not compatible with this SDK version.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.MODEL_NOT_INITIALIZED","title":"<code>MODEL_NOT_INITIALIZED = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Model must be initialized before this operation.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.NULL_POINTER","title":"<code>NULL_POINTER = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Required pointer argument was NULL.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.PARAMETER_FIXED","title":"<code>PARAMETER_FIXED = 8</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The requested parameter is read-only for this model type and cannot be modified.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.PARAMETER_OUT_OF_RANGE","title":"<code>PARAMETER_OUT_OF_RANGE = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Parameter value is outside acceptable range.</p>"},{"location":"low-level-bindings/#aic._bindings.AICErrorCode.SUCCESS","title":"<code>SUCCESS = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Operation completed successfully.</p>"},{"location":"low-level-bindings/#aic._bindings.AICModelType","title":"<code>aic._bindings.AICModelType</code>","text":"<p>Available model types for audio enhancement.</p> <p>Each model is optimized for a native sample rate and frame size and has a characteristic processing latency.</p>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_L16","title":"<code>QUAIL_L16 = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 16 kHz</li> <li>Native num frames: 160</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_L48","title":"<code>QUAIL_L48 = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 48 kHz</li> <li>Native num frames: 480</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_L8","title":"<code>QUAIL_L8 = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 8 kHz</li> <li>Native num frames: 80</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_S16","title":"<code>QUAIL_S16 = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 16 kHz</li> <li>Native num frames: 160</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_S48","title":"<code>QUAIL_S48 = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 48 kHz</li> <li>Native num frames: 480</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_S8","title":"<code>QUAIL_S8 = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 8 kHz</li> <li>Native num frames: 80</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_STT_L16","title":"<code>QUAIL_STT_L16 = 8</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Special model optimized for human-to-machine interaction (e.g., voice agents, speech-to-text) designed specifically to improve STT accuracy across unpredictable, diverse and challenging environments.</p> <p>Specifications:</p> <ul> <li>Window length: 10 ms</li> <li>Native sample rate: 16 kHz</li> <li>Native num frames: 160</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_STT_L8","title":"<code>QUAIL_STT_L8 = 9</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Special model optimized for human-to-machine interaction (e.g., voice agents, speech-to-text) designed specifically to improve STT accuracy across unpredictable, diverse and challenging environments.</p> <p>Specifications:</p> <ul> <li>Window length: 10 ms</li> <li>Native sample rate: 8 kHz</li> <li>Native num frames: 80</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_STT_S16","title":"<code>QUAIL_STT_S16 = 10</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Special model optimized for human-to-machine interaction (e.g., voice agents, speech-to-text) designed specifically to improve STT accuracy across unpredictable, diverse and challenging environments.</p> <p>Specifications:</p> <ul> <li>Window length: 10 ms</li> <li>Native sample rate: 16 kHz</li> <li>Native num frames: 160</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_STT_S8","title":"<code>QUAIL_STT_S8 = 11</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Special model optimized for human-to-machine interaction (e.g., voice agents, speech-to-text) designed specifically to improve STT accuracy across unpredictable, diverse and challenging environments.</p> <p>Specifications:</p> <ul> <li>Window length: 10 ms</li> <li>Native sample rate: 8 kHz</li> <li>Native num frames: 80</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_VF_STT_L16","title":"<code>QUAIL_VF_STT_L16 = 12</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Special model optimized for human-to-machine interaction (e.g., voice agents, speech-to-text) purpose-built to isolate and elevate the foreground speaker while suppressing both interfering speech and background noise.</p> <p>Specifications:</p> <ul> <li>Window length: 10 ms</li> <li>Native sample rate: 16 kHz</li> <li>Native num frames: 160</li> <li>Processing latency: 30 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_XS","title":"<code>QUAIL_XS = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 48 kHz</li> <li>Native num frames: 480</li> <li>Processing latency: 10 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICModelType.QUAIL_XXS","title":"<code>QUAIL_XXS = 7</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specifications:</p> <ul> <li>Native sample rate: 48 kHz</li> <li>Native num frames: 480</li> <li>Processing latency: 10 ms</li> </ul>"},{"location":"low-level-bindings/#aic._bindings.AICEnhancementParameter","title":"<code>aic._bindings.AICEnhancementParameter</code>","text":"<p>Configurable parameters for audio enhancement.</p>"},{"location":"low-level-bindings/#aic._bindings.AICEnhancementParameter.BYPASS","title":"<code>BYPASS = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Bypass audio processing while preserving algorithmic delay.</p> <p>Range: 0.0 \u2026 1.0</p> <ul> <li>0.0: Enhancement active (normal processing)</li> <li>1.0: Bypass enabled (latency-compensated passthrough)</li> </ul> <p>Default: 0.0</p>"},{"location":"low-level-bindings/#aic._bindings.AICEnhancementParameter.ENHANCEMENT_LEVEL","title":"<code>ENHANCEMENT_LEVEL = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Controls the intensity of speech enhancement processing.</p> <p>Range: 0.0 \u2026 1.0</p> <ul> <li>0.0: No enhancement</li> <li>1.0: Full enhancement (maximum noise reduction, potentially more artifacts)</li> </ul> <p>Default: 1.0</p>"},{"location":"low-level-bindings/#aic._bindings.AICEnhancementParameter.NOISE_GATE_ENABLE","title":"<code>NOISE_GATE_ENABLE = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Enable or disable a noise gate as a post-processing step.</p> <p>Valid values: 0.0 or 1.0</p> <ul> <li>0.0: Noise gate disabled</li> <li>1.0: Noise gate enabled</li> </ul> <p>Default: 0.0</p>"},{"location":"low-level-bindings/#aic._bindings.AICEnhancementParameter.VOICE_GAIN","title":"<code>VOICE_GAIN = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compensates for perceived volume reduction after noise removal.</p> <p>Range: 0.1 \u2026 4.0 (linear amplitude multiplier)</p> <ul> <li>0.1: Significant volume reduction (\u2248 -20 dB)</li> <li>1.0: No gain change (0 dB, default)</li> <li>2.0: Double amplitude (+6 dB)</li> <li>4.0: Maximum boost (+12 dB)</li> </ul> <p>Formula: gain_dB = 20 * log10(value) Default: 1.0</p>"},{"location":"low-level-bindings/#aic._bindings.AICParameter","title":"<code>aic._bindings.AICParameter = AICEnhancementParameter</code>  <code>module-attribute</code>","text":""},{"location":"low-level-bindings/#aic._bindings.AICVadParameter","title":"<code>aic._bindings.AICVadParameter</code>","text":"<p>Configurable parameters for Voice Activity Detection (VAD).</p>"},{"location":"low-level-bindings/#aic._bindings.AICVadParameter.MINIMUM_SPEECH_DURATION","title":"<code>MINIMUM_SPEECH_DURATION = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Controls for how long speech needs to be present before the VAD considers it speech.</p> <p>This affects the stability of speech not detected -&gt; detected transitions.</p> <p>NOTE: The VAD returns a value per processed buffer, so this duration is rounded to the closest buffer. For example, if the model is initialized to process audio in chunks of 10 ms, the VAD will round up/down to the closest multiple of 10 ms. Because of this, this parameter may return a different value than the one it was last set to.</p> <p>Range: 0.0 \u2026 1.0 (value in seconds) Default: 0.0</p>"},{"location":"low-level-bindings/#aic._bindings.AICVadParameter.SENSITIVITY","title":"<code>SENSITIVITY = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Controls the sensitivity (energy threshold) of the VAD.</p> <p>This value is used by the VAD as the threshold a speech audio signal's energy has to exceed in order to be considered speech.</p> <p>Range: 1.0 to 15.0</p> <p>Formula: Energy threshold = 10 ^ (-sensitivity)</p> <p>Default: 6.0</p>"},{"location":"low-level-bindings/#aic._bindings.AICVadParameter.SPEECH_HOLD_DURATION","title":"<code>SPEECH_HOLD_DURATION = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Controls for how long the VAD continues to detect speech after the audio signal no longer contains speech.</p> <p>The VAD reports speech detected if the audio signal contained speech in at least 50% of the frames processed in the last <code>speech_hold_duration</code> seconds.</p> <p>This affects the stability of speech detected -&gt; not detected transitions.</p> <p>NOTE: The VAD returns a value per processed buffer, so this duration is rounded to the closest model window length. For example, if the model has a processing window length of 10 ms, the VAD will round up/down to the closest multiple of 10 ms. Because of this, this parameter may return a different value than the one it was last set to.</p> <p>Range: 0.0 to 20x model window length (value in seconds)</p> <p>Default: 0.05</p>"}]}